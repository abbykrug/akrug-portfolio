{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RHuyiiQn1s5"
   },
   "source": [
    "# **AI Powered HR Assistant**\n",
    "\n",
    "By: Abby Krug\n",
    "\n",
    "11/10/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4JKi6e7n1s6"
   },
   "source": [
    "Import/Install Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3RZJRSan1s7",
    "outputId": "6b56e571-c244-4853-e52b-03d5b1515d8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in ./.local/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.local/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/site-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.local/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.local/lib/python3.10/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.local/lib/python3.10/site-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.local/lib/python3.10/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install the necessary modules\n",
    "# %pip install --upgrade huggingface_hub sentence-transformers bitsandbytes\n",
    "%pip install -qU pypdf\n",
    "%pip install -qU langchain langchain-community langchain-google-genai langchain-text-splitters langchain-openai\n",
    "%pip install -qU faiss-cpu\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4liu6_kMn1s8"
   },
   "outputs": [],
   "source": [
    "# import the necessary modules\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will load openai and load the API Key from this lab allowing me to use the embeddings and llm\n",
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SKYgI-J3oC4A"
   },
   "outputs": [],
   "source": [
    "# I used this when I was trying to use Gemini but I ran into overused API Key calls issue...\n",
    "\n",
    "#from google import genai\n",
    "#from getpass import getpass\n",
    "#api_key = getpass()\n",
    "#client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dY91SXqkn1s8"
   },
   "source": [
    "**LOAD Documents (PDFs)**\n",
    "\n",
    "Need to load the information for the nestle HR policy chatbot to enable access from RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-N0GZ_w_n1s9"
   },
   "outputs": [],
   "source": [
    "# This step will load the pdf for the hr policy that will be loaded into the vector store\n",
    "\n",
    "loader = PyPDFLoader(\"nestle_hr_policy_pdf_2012.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P02l5lgn1s9"
   },
   "source": [
    "**SPLIT Text into Smaller Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_iNBzgRYn1s9",
    "outputId": "4f7392b8-4796-41b6-94c3-a58bfa7d830b"
   },
   "outputs": [],
   "source": [
    "# This step splits the pdf into smaller text chunks\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=32)\n",
    "all_txt = doc_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "135-Jj9Ln1s9"
   },
   "source": [
    "**EMBED all of the chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "sE6PN8b40U2g"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wJ-cwM3Vp63K"
   },
   "outputs": [],
   "source": [
    "# This was when I was using Gemini Embeddings but I was running into issues with my API key...\n",
    "# Initialize the GoogleGenerativeAIEmbeddings model with the API key\n",
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\", google_api_key=api_key)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kholVW8ln1s-"
   },
   "source": [
    "**BUILD Vector Store and Cast it as a Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pkOBd68Cn1s-"
   },
   "outputs": [],
   "source": [
    "# need to import the vector stores before building through langchain\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "9KijcU4Yup10",
    "outputId": "500cc1fb-61d9-45bd-ef97-518cc36dc5fe"
   },
   "outputs": [],
   "source": [
    "# This step uses FAISS to load the vectorstore and cast it as a retriever\n",
    "\n",
    "vs = FAISS.from_documents(all_txt, embeddings)\n",
    "lab=vs.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxqGQOUun1s-"
   },
   "source": [
    "**DESIGN Prompt Template for LLM**\n",
    "\n",
    "For this template I included that the LLM should act as a conversational HR Policy Chatbot. The placeholders are context and question. Context will be filled by my RAG function and Question will be filled by the Gradio UI that will ask the user for a question for the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "zZMufLbfn1s_"
   },
   "outputs": [],
   "source": [
    "# import langchain prompts for templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RRh93nd9n1s_"
   },
   "outputs": [],
   "source": [
    "# This step will create a template prompt which will be sent to the LLM\n",
    "\n",
    "temp=\"\"\"You are a conversational chatbot for question-answering tasks.\n",
    "You work for Nestle Human Resources.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use one sentence and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(temp)\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_rNAb1cn1s_"
   },
   "source": [
    "**LOAD and CONFIGURE LLM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oqb0XE76n1s_"
   },
   "outputs": [],
   "source": [
    "# this cell was for when I tried to use Gemini but was running into API Key issues...\n",
    "\n",
    "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "#llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step loads the OpenAI llm to use for the chain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqoC7hCRn1s_"
   },
   "source": [
    "**SET up pipeline and chain components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "habkGfhgn1s_"
   },
   "outputs": [],
   "source": [
    "# need to connect the chain together\n",
    "rag_chain = (\n",
    "    {\"context\": lab, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "# this function will execute the chain and return the chatbot response\n",
    "def rag_chain_fn(message):\n",
    "    response = rag_chain.invoke(message)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tVyWZNLn1tA"
   },
   "source": [
    "**Create Gradio UI and ask user for query**\n",
    "\n",
    "This Gradio UI will have chatbot. The query listed in the textbox will spark the chain to run and then return the chatbot answer to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUVoRWmZn1tA",
    "outputId": "8b289510-98dd-4fc1-af12-1855f23c5cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/site-packages (4.7.1)\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.49.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./.local/lib/python3.10/site-packages (from gradio) (3.7.1)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading brotli-1.2.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.121.3-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/site-packages (from gradio) (0.3.1)\n",
      "Collecting gradio-client==1.13.3 (from gradio)\n",
      "  Downloading gradio_client-1.13.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in ./.local/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5 (from gradio)\n",
      "  Downloading huggingface_hub-1.1.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from gradio) (1.26.2)\n",
      "Requirement already satisfied: orjson~=3.0 in ./.local/lib/python3.10/site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/site-packages (from gradio) (10.1.0)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.14.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./.local/lib/python3.10/site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/site-packages (from gradio) (0.24.0.post1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from gradio-client==1.13.3->gradio) (2023.10.0)\n",
      "Collecting websockets<16.0,>=13.0 (from gradio-client==1.13.3->gradio)\n",
      "  Using cached websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.2->gradio)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.13.1)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.66.1)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.1)\n",
      "Downloading gradio-5.49.1-py3-none-any.whl (63.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.13.3-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading brotli-1.2.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.121.3-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-1.1.4-py3-none-any.whl (515 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.6/515.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.14.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m839.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m877.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: brotli, websockets, typer-slim, ruff, python-multipart, pydantic-core, hf-xet, groovy, annotated-doc, starlette, pydantic, typer, safehttpx, huggingface-hub, fastapi, gradio-client, gradio\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 11.0.3\n",
      "    Uninstalling websockets-11.0.3:\n",
      "      Successfully uninstalled websockets-11.0.3\n",
      "\u001b[33m  WARNING: The script websockets is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.41.5\n",
      "    Uninstalling pydantic_core-2.41.5:\n",
      "      Successfully uninstalled pydantic_core-2.41.5\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/voc/work/.local/lib/python3.10/site-packages/~ydantic_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.12.4\n",
      "    Uninstalling pydantic-2.12.4:\n",
      "      Successfully uninstalled pydantic-2.12.4\n",
      "\u001b[33m  WARNING: The script typer is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts hf and tiny-agents are installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script fastapi is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-genai 1.50.1 requires anyio<5.0.0,>=4.8.0, but you have anyio 3.7.1 which is incompatible.\n",
      "confection 0.0.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.11.10 which is incompatible.\n",
      "spacy 3.5.1 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.11.10 which is incompatible.\n",
      "spacy 3.5.1 requires typer<0.8.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.\n",
      "thinc 8.1.9 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.11.10 which is incompatible.\n",
      "tokenizers 0.15.0 requires huggingface_hub<1.0,>=0.16.4, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "transformers 4.35.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.2 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.1.3 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.11.10 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-doc-0.0.4 brotli-1.2.0 fastapi-0.121.3 gradio-5.49.1 gradio-client-1.13.3 groovy-0.1.2 hf-xet-1.2.0 huggingface-hub-1.1.4 pydantic-2.11.10 pydantic-core-2.33.2 python-multipart-0.0.20 ruff-0.14.5 safehttpx-0.1.7 starlette-0.50.0 typer-0.20.0 typer-slim-0.20.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# need to install gradio\n",
    "%pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "HxM-VACrn1tA",
    "outputId": "d8f4e623-9478-44c6-fdfb-339437a546e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://1524eab57ee9bbea9c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1524eab57ee9bbea9c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# this is required for the syntax of ChatInterface\n",
    "def chat_bot(message, history):\n",
    "    response = rag_chain_fn(message)\n",
    "    return response\n",
    "\n",
    "# trigger function that invokes rag_chain\n",
    "g = gr.ChatInterface(\n",
    "   fn = chat_bot,\n",
    "   title = \"NESTLE HR Chatbot\",\n",
    "   description = \"Ask questions about the Nestle HR Policy\",\n",
    "   theme = \"soft\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  g.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
